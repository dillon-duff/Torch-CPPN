RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=25, bias=True)
    (1): ReLU()
    (2): Linear(in_features=25, out_features=21, bias=True)
    (3): Tanhshrink()
    (4): Linear(in_features=21, out_features=2, bias=True)
    (5): Identity()
    (6): Linear(in_features=2, out_features=68, bias=True)
    (7): Sigmoid()
    (8): Linear(in_features=68, out_features=35, bias=True)
    (9): GELU(approximate='none')
    (10): Linear(in_features=35, out_features=69, bias=True)
    (11): LeakyReLU(negative_slope=0.01)
    (12): Linear(in_features=69, out_features=94, bias=True)
    (13): Mish()
    (14): Linear(in_features=94, out_features=82, bias=True)
    (15): Hardshrink(0.5)
    (16): Linear(in_features=82, out_features=39, bias=True)
    (17): ReLU6()
    (18): Linear(in_features=39, out_features=92, bias=True)
    (19): Hardswish()
    (20): Linear(in_features=92, out_features=51, bias=True)
    (21): Hardtanh(min_val=-1.0, max_val=1.0)
    (22): Linear(in_features=51, out_features=47, bias=True)
    (23): SiLU()
    (24): Linear(in_features=47, out_features=83, bias=True)
    (25): Hardswish()
    (26): Linear(in_features=83, out_features=22, bias=True)
    (27): LogSigmoid()
    (28): Linear(in_features=22, out_features=1, bias=True)
    (29): SELU()
  )
)