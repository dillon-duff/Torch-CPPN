RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=199, bias=True)
    (1): Softsign()
    (2): Linear(in_features=199, out_features=541, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=541, out_features=40, bias=True)
    (5): Hardsigmoid()
    (6): Linear(in_features=40, out_features=440, bias=True)
    (7): CELU(alpha=1.0)
    (8): Linear(in_features=440, out_features=898, bias=True)
    (9): Softplus(beta=1, threshold=20)
    (10): Linear(in_features=898, out_features=954, bias=True)
    (11): Softsign()
    (12): Linear(in_features=954, out_features=509, bias=True)
    (13): GELU(approximate='none')
    (14): Linear(in_features=509, out_features=420, bias=True)
    (15): Mish()
    (16): Linear(in_features=420, out_features=971, bias=True)
    (17): CELU(alpha=1.0)
    (18): Linear(in_features=971, out_features=635, bias=True)
    (19): CELU(alpha=1.0)
    (20): Linear(in_features=635, out_features=327, bias=True)
    (21): Hardsigmoid()
    (22): Linear(in_features=327, out_features=195, bias=True)
    (23): SiLU()
    (24): Linear(in_features=195, out_features=646, bias=True)
    (25): RReLU(lower=0.125, upper=0.3333333333333333)
    (26): Linear(in_features=646, out_features=177, bias=True)
    (27): ReLU()
    (28): Linear(in_features=177, out_features=1, bias=True)
    (29): Hardtanh(min_val=-1.0, max_val=1.0)
  )
)