RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=7, bias=True)
    (1): Tanhshrink()
    (2): Linear(in_features=7, out_features=370, bias=True)
    (3): Hardsigmoid()
    (4): Linear(in_features=370, out_features=947, bias=True)
    (5): Mish()
    (6): Linear(in_features=947, out_features=773, bias=True)
    (7): SELU()
    (8): Linear(in_features=773, out_features=908, bias=True)
    (9): Hardtanh(min_val=-1.0, max_val=1.0)
    (10): Linear(in_features=908, out_features=442, bias=True)
    (11): Sigmoid()
    (12): Linear(in_features=442, out_features=744, bias=True)
    (13): ELU(alpha=1.0)
    (14): Linear(in_features=744, out_features=958, bias=True)
    (15): Softplus(beta=1, threshold=20)
    (16): Linear(in_features=958, out_features=930, bias=True)
    (17): Mish()
    (18): Linear(in_features=930, out_features=473, bias=True)
    (19): ReLU6()
    (20): Linear(in_features=473, out_features=336, bias=True)
    (21): Tanhshrink()
    (22): Linear(in_features=336, out_features=28, bias=True)
    (23): LeakyReLU(negative_slope=0.01)
    (24): Linear(in_features=28, out_features=947, bias=True)
    (25): LogSigmoid()
    (26): Linear(in_features=947, out_features=242, bias=True)
    (27): GELU(approximate='none')
    (28): Linear(in_features=242, out_features=941, bias=True)
    (29): Tanhshrink()
    (30): Linear(in_features=941, out_features=341, bias=True)
    (31): Softshrink(0.5)
    (32): Linear(in_features=341, out_features=1, bias=True)
    (33): CELU(alpha=1.0)
  )
)