RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=49, bias=True)
    (1): Hardsigmoid()
    (2): Linear(in_features=49, out_features=11, bias=True)
    (3): Tanh()
    (4): Linear(in_features=11, out_features=10, bias=True)
    (5): Softshrink(0.5)
    (6): Linear(in_features=10, out_features=25, bias=True)
    (7): Tanhshrink()
    (8): Linear(in_features=25, out_features=42, bias=True)
    (9): ELU(alpha=1.0)
    (10): Linear(in_features=42, out_features=25, bias=True)
    (11): ELU(alpha=1.0)
    (12): Linear(in_features=25, out_features=33, bias=True)
    (13): PReLU(num_parameters=1)
    (14): Linear(in_features=33, out_features=5, bias=True)
    (15): PReLU(num_parameters=1)
    (16): Linear(in_features=5, out_features=37, bias=True)
    (17): ReLU6()
    (18): Linear(in_features=37, out_features=37, bias=True)
    (19): Hardtanh(min_val=-1.0, max_val=1.0)
    (20): Linear(in_features=37, out_features=27, bias=True)
    (21): Softshrink(0.5)
    (22): Linear(in_features=27, out_features=27, bias=True)
    (23): Hardswish()
    (24): Linear(in_features=27, out_features=32, bias=True)
    (25): LeakyReLU(negative_slope=0.01)
    (26): Linear(in_features=32, out_features=32, bias=True)
    (27): Hardshrink(0.5)
    (28): Linear(in_features=32, out_features=1, bias=True)
    (29): Softshrink(0.5)
  )
)