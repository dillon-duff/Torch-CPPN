RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=130, bias=True)
    (1): Softshrink(0.5)
    (2): Linear(in_features=130, out_features=27, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=27, out_features=136, bias=True)
    (5): PReLU(num_parameters=1)
    (6): Linear(in_features=136, out_features=10, bias=True)
    (7): Sigmoid()
    (8): Linear(in_features=10, out_features=15, bias=True)
    (9): Softplus(beta=1, threshold=20)
    (10): Linear(in_features=15, out_features=109, bias=True)
    (11): RReLU(lower=0.125, upper=0.3333333333333333)
    (12): Linear(in_features=109, out_features=12, bias=True)
    (13): Tanhshrink()
    (14): Linear(in_features=12, out_features=122, bias=True)
    (15): GELU(approximate='none')
    (16): Linear(in_features=122, out_features=80, bias=True)
    (17): ReLU()
    (18): Linear(in_features=80, out_features=2, bias=True)
    (19): SELU()
    (20): Linear(in_features=2, out_features=21, bias=True)
    (21): SELU()
    (22): Linear(in_features=21, out_features=51, bias=True)
    (23): GELU(approximate='none')
    (24): Linear(in_features=51, out_features=27, bias=True)
    (25): RReLU(lower=0.125, upper=0.3333333333333333)
    (26): Linear(in_features=27, out_features=1, bias=True)
    (27): Sigmoid()
  )
)