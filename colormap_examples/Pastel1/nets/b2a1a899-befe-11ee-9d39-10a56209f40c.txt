RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=36, bias=True)
    (1): LogSigmoid()
    (2): Linear(in_features=36, out_features=14, bias=True)
    (3): SiLU()
    (4): Linear(in_features=14, out_features=46, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=46, out_features=36, bias=True)
    (7): RReLU(lower=0.125, upper=0.3333333333333333)
    (8): Linear(in_features=36, out_features=69, bias=True)
    (9): RReLU(lower=0.125, upper=0.3333333333333333)
    (10): Linear(in_features=69, out_features=54, bias=True)
    (11): Tanh()
    (12): Linear(in_features=54, out_features=51, bias=True)
    (13): CELU(alpha=1.0)
    (14): Linear(in_features=51, out_features=68, bias=True)
    (15): RReLU(lower=0.125, upper=0.3333333333333333)
    (16): Linear(in_features=68, out_features=56, bias=True)
    (17): PReLU(num_parameters=1)
    (18): Linear(in_features=56, out_features=116, bias=True)
    (19): Tanh()
    (20): Linear(in_features=116, out_features=126, bias=True)
    (21): LeakyReLU(negative_slope=0.01)
    (22): Linear(in_features=126, out_features=92, bias=True)
    (23): Hardswish()
    (24): Linear(in_features=92, out_features=1, bias=True)
    (25): Sigmoid()
  )
)