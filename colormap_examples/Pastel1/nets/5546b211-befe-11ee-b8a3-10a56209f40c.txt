RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=143, bias=True)
    (1): Hardswish()
    (2): Linear(in_features=143, out_features=22, bias=True)
    (3): SiLU()
    (4): Linear(in_features=22, out_features=31, bias=True)
    (5): RReLU(lower=0.125, upper=0.3333333333333333)
    (6): Linear(in_features=31, out_features=147, bias=True)
    (7): Hardshrink(0.5)
    (8): Linear(in_features=147, out_features=106, bias=True)
    (9): PReLU(num_parameters=1)
    (10): Linear(in_features=106, out_features=99, bias=True)
    (11): Hardsigmoid()
    (12): Linear(in_features=99, out_features=74, bias=True)
    (13): Sigmoid()
    (14): Linear(in_features=74, out_features=74, bias=True)
    (15): LogSigmoid()
    (16): Linear(in_features=74, out_features=79, bias=True)
    (17): Mish()
    (18): Linear(in_features=79, out_features=30, bias=True)
    (19): GELU(approximate='none')
    (20): Linear(in_features=30, out_features=57, bias=True)
    (21): Hardtanh(min_val=-1.0, max_val=1.0)
    (22): Linear(in_features=57, out_features=126, bias=True)
    (23): Sigmoid()
    (24): Linear(in_features=126, out_features=35, bias=True)
    (25): Softplus(beta=1, threshold=20)
    (26): Linear(in_features=35, out_features=1, bias=True)
    (27): LogSigmoid()
  )
)