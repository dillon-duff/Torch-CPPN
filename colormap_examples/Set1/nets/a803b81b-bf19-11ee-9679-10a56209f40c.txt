RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=133, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=133, out_features=79, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=79, out_features=13, bias=True)
    (5): ReLU6()
    (6): Linear(in_features=13, out_features=107, bias=True)
    (7): LogSigmoid()
    (8): Linear(in_features=107, out_features=9, bias=True)
    (9): Softplus(beta=1, threshold=20)
    (10): Linear(in_features=9, out_features=137, bias=True)
    (11): ReLU6()
    (12): Linear(in_features=137, out_features=3, bias=True)
    (13): Hardtanh(min_val=-1.0, max_val=1.0)
    (14): Linear(in_features=3, out_features=140, bias=True)
    (15): Hardsigmoid()
    (16): Linear(in_features=140, out_features=122, bias=True)
    (17): CELU(alpha=1.0)
    (18): Linear(in_features=122, out_features=119, bias=True)
    (19): Softplus(beta=1, threshold=20)
    (20): Linear(in_features=119, out_features=120, bias=True)
    (21): CELU(alpha=1.0)
    (22): Linear(in_features=120, out_features=82, bias=True)
    (23): PReLU(num_parameters=1)
    (24): Linear(in_features=82, out_features=10, bias=True)
    (25): Tanh()
    (26): Linear(in_features=10, out_features=1, bias=True)
    (27): Hardtanh(min_val=-1.0, max_val=1.0)
  )
)