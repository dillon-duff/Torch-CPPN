RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=769, bias=True)
    (1): ReLU()
    (2): Linear(in_features=769, out_features=348, bias=True)
    (3): Softsign()
    (4): Linear(in_features=348, out_features=218, bias=True)
    (5): LogSigmoid()
    (6): Linear(in_features=218, out_features=609, bias=True)
    (7): Sigmoid()
    (8): Linear(in_features=609, out_features=633, bias=True)
    (9): LeakyReLU(negative_slope=0.01)
    (10): Linear(in_features=633, out_features=989, bias=True)
    (11): Softshrink(0.5)
    (12): Linear(in_features=989, out_features=635, bias=True)
    (13): CELU(alpha=1.0)
    (14): Linear(in_features=635, out_features=779, bias=True)
    (15): RReLU(lower=0.125, upper=0.3333333333333333)
    (16): Linear(in_features=779, out_features=211, bias=True)
    (17): Sigmoid()
    (18): Linear(in_features=211, out_features=350, bias=True)
    (19): Softsign()
    (20): Linear(in_features=350, out_features=414, bias=True)
    (21): Softsign()
    (22): Linear(in_features=414, out_features=272, bias=True)
    (23): Softplus(beta=1, threshold=20)
    (24): Linear(in_features=272, out_features=176, bias=True)
    (25): RReLU(lower=0.125, upper=0.3333333333333333)
    (26): Linear(in_features=176, out_features=1, bias=True)
    (27): Tanh()
  )
)