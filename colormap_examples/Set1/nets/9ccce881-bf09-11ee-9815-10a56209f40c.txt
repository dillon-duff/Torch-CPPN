RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=104, bias=True)
    (1): Sigmoid()
    (2): Linear(in_features=104, out_features=144, bias=True)
    (3): Hardtanh(min_val=-1.0, max_val=1.0)
    (4): Linear(in_features=144, out_features=179, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Linear(in_features=179, out_features=125, bias=True)
    (7): CELU(alpha=1.0)
    (8): Linear(in_features=125, out_features=178, bias=True)
    (9): ReLU6()
    (10): Linear(in_features=178, out_features=153, bias=True)
    (11): RReLU(lower=0.125, upper=0.3333333333333333)
    (12): Linear(in_features=153, out_features=189, bias=True)
    (13): Sigmoid()
    (14): Linear(in_features=189, out_features=194, bias=True)
    (15): Hardswish()
    (16): Linear(in_features=194, out_features=178, bias=True)
    (17): ReLU()
    (18): Linear(in_features=178, out_features=139, bias=True)
    (19): Hardtanh(min_val=-1.0, max_val=1.0)
    (20): Linear(in_features=139, out_features=161, bias=True)
    (21): Hardtanh(min_val=-1.0, max_val=1.0)
    (22): Linear(in_features=161, out_features=158, bias=True)
    (23): SELU()
    (24): Linear(in_features=158, out_features=105, bias=True)
    (25): Sigmoid()
    (26): Linear(in_features=105, out_features=1, bias=True)
    (27): Hardtanh(min_val=-1.0, max_val=1.0)
  )
)