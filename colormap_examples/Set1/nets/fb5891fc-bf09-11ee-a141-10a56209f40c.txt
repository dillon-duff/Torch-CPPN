RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=10, bias=True)
    (1): PReLU(num_parameters=1)
    (2): Linear(in_features=10, out_features=67, bias=True)
    (3): Hardtanh(min_val=-1.0, max_val=1.0)
    (4): Linear(in_features=67, out_features=20, bias=True)
    (5): SiLU()
    (6): Linear(in_features=20, out_features=48, bias=True)
    (7): Tanhshrink()
    (8): Linear(in_features=48, out_features=59, bias=True)
    (9): Hardshrink(0.5)
    (10): Linear(in_features=59, out_features=50, bias=True)
    (11): GELU(approximate='none')
    (12): Linear(in_features=50, out_features=80, bias=True)
    (13): Hardsigmoid()
    (14): Linear(in_features=80, out_features=16, bias=True)
    (15): Sigmoid()
    (16): Linear(in_features=16, out_features=43, bias=True)
    (17): Tanhshrink()
    (18): Linear(in_features=43, out_features=41, bias=True)
    (19): LogSigmoid()
    (20): Linear(in_features=41, out_features=59, bias=True)
    (21): Hardswish()
    (22): Linear(in_features=59, out_features=91, bias=True)
    (23): PReLU(num_parameters=1)
    (24): Linear(in_features=91, out_features=92, bias=True)
    (25): ReLU()
    (26): Linear(in_features=92, out_features=66, bias=True)
    (27): Hardtanh(min_val=-1.0, max_val=1.0)
    (28): Linear(in_features=66, out_features=32, bias=True)
    (29): Tanh()
    (30): Linear(in_features=32, out_features=18, bias=True)
    (31): CELU(alpha=1.0)
    (32): Linear(in_features=18, out_features=65, bias=True)
    (33): Hardsigmoid()
    (34): Linear(in_features=65, out_features=82, bias=True)
    (35): Hardswish()
    (36): Linear(in_features=82, out_features=45, bias=True)
    (37): Hardswish()
    (38): Linear(in_features=45, out_features=22, bias=True)
    (39): LeakyReLU(negative_slope=0.01)
    (40): Linear(in_features=22, out_features=37, bias=True)
    (41): CELU(alpha=1.0)
    (42): Linear(in_features=37, out_features=1, bias=True)
    (43): LogSigmoid()
  )
)