RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=126, bias=True)
    (1): ReLU6()
    (2): Linear(in_features=126, out_features=95, bias=True)
    (3): Sigmoid()
    (4): Linear(in_features=95, out_features=18, bias=True)
    (5): Hardswish()
    (6): Linear(in_features=18, out_features=15, bias=True)
    (7): Softplus(beta=1, threshold=20)
    (8): Linear(in_features=15, out_features=81, bias=True)
    (9): LeakyReLU(negative_slope=0.01)
    (10): Linear(in_features=81, out_features=2, bias=True)
    (11): SiLU()
    (12): Linear(in_features=2, out_features=20, bias=True)
    (13): Hardtanh(min_val=-1.0, max_val=1.0)
    (14): Linear(in_features=20, out_features=106, bias=True)
    (15): LeakyReLU(negative_slope=0.01)
    (16): Linear(in_features=106, out_features=10, bias=True)
    (17): Hardsigmoid()
    (18): Linear(in_features=10, out_features=43, bias=True)
    (19): CELU(alpha=1.0)
    (20): Linear(in_features=43, out_features=100, bias=True)
    (21): Softplus(beta=1, threshold=20)
    (22): Linear(in_features=100, out_features=25, bias=True)
    (23): Hardshrink(0.5)
    (24): Linear(in_features=25, out_features=1, bias=True)
    (25): RReLU(lower=0.125, upper=0.3333333333333333)
  )
)