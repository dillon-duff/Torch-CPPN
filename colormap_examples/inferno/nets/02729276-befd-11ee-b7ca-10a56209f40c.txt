RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=135, bias=True)
    (1): LogSigmoid()
    (2): Linear(in_features=135, out_features=26, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=26, out_features=130, bias=True)
    (5): Hardtanh(min_val=-1.0, max_val=1.0)
    (6): Linear(in_features=130, out_features=11, bias=True)
    (7): SiLU()
    (8): Linear(in_features=11, out_features=103, bias=True)
    (9): SiLU()
    (10): Linear(in_features=103, out_features=47, bias=True)
    (11): GELU(approximate='none')
    (12): Linear(in_features=47, out_features=150, bias=True)
    (13): Softsign()
    (14): Linear(in_features=150, out_features=86, bias=True)
    (15): Hardsigmoid()
    (16): Linear(in_features=86, out_features=18, bias=True)
    (17): Hardshrink(0.5)
    (18): Linear(in_features=18, out_features=96, bias=True)
    (19): Softplus(beta=1, threshold=20)
    (20): Linear(in_features=96, out_features=20, bias=True)
    (21): GELU(approximate='none')
    (22): Linear(in_features=20, out_features=115, bias=True)
    (23): SiLU()
    (24): Linear(in_features=115, out_features=150, bias=True)
    (25): CELU(alpha=1.0)
    (26): Linear(in_features=150, out_features=1, bias=True)
    (27): RReLU(lower=0.125, upper=0.3333333333333333)
  )
)