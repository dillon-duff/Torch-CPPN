RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=101, bias=True)
    (1): CELU(alpha=1.0)
    (2): Linear(in_features=101, out_features=5, bias=True)
    (3): CELU(alpha=1.0)
    (4): Linear(in_features=5, out_features=2, bias=True)
    (5): SELU()
    (6): Linear(in_features=2, out_features=7, bias=True)
    (7): LogSigmoid()
    (8): Linear(in_features=7, out_features=3, bias=True)
    (9): RReLU(lower=0.125, upper=0.3333333333333333)
    (10): Linear(in_features=3, out_features=5, bias=True)
    (11): Mish()
    (12): Linear(in_features=5, out_features=15, bias=True)
    (13): Tanhshrink()
    (14): Linear(in_features=15, out_features=11, bias=True)
    (15): CELU(alpha=1.0)
    (16): Linear(in_features=11, out_features=128, bias=True)
    (17): Tanh()
    (18): Linear(in_features=128, out_features=149, bias=True)
    (19): Softplus(beta=1, threshold=20)
    (20): Linear(in_features=149, out_features=119, bias=True)
    (21): CELU(alpha=1.0)
    (22): Linear(in_features=119, out_features=117, bias=True)
    (23): PReLU(num_parameters=1)
    (24): Linear(in_features=117, out_features=1, bias=True)
    (25): ReLU()
    (26): Linear(in_features=1, out_features=1, bias=True)
    (27): Tanhshrink()
  )
)