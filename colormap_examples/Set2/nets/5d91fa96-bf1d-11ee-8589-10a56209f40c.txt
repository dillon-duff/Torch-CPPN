RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=1, bias=True)
    (1): Identity()
    (2): Linear(in_features=1, out_features=115, bias=True)
    (3): Mish()
    (4): Linear(in_features=115, out_features=3, bias=True)
    (5): CELU(alpha=1.0)
    (6): Linear(in_features=3, out_features=112, bias=True)
    (7): Identity()
    (8): Linear(in_features=112, out_features=15, bias=True)
    (9): GELU(approximate='none')
    (10): Linear(in_features=15, out_features=112, bias=True)
    (11): LogSigmoid()
    (12): Linear(in_features=112, out_features=140, bias=True)
    (13): LogSigmoid()
    (14): Linear(in_features=140, out_features=140, bias=True)
    (15): LogSigmoid()
    (16): Linear(in_features=140, out_features=10, bias=True)
    (17): ELU(alpha=1.0)
    (18): Linear(in_features=10, out_features=3, bias=True)
    (19): ELU(alpha=1.0)
    (20): Linear(in_features=3, out_features=84, bias=True)
    (21): Hardtanh(min_val=-1.0, max_val=1.0)
    (22): Linear(in_features=84, out_features=131, bias=True)
    (23): Softshrink(0.5)
    (24): Linear(in_features=131, out_features=89, bias=True)
    (25): RReLU(lower=0.125, upper=0.3333333333333333)
    (26): Linear(in_features=89, out_features=1, bias=True)
    (27): ReLU()
  )
)