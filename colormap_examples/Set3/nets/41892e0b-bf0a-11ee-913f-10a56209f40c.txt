RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=82, bias=True)
    (1): Tanh()
    (2): Linear(in_features=82, out_features=8, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=8, out_features=46, bias=True)
    (5): ELU(alpha=1.0)
    (6): Linear(in_features=46, out_features=66, bias=True)
    (7): LeakyReLU(negative_slope=0.01)
    (8): Linear(in_features=66, out_features=68, bias=True)
    (9): GELU(approximate='none')
    (10): Linear(in_features=68, out_features=36, bias=True)
    (11): ReLU()
    (12): Linear(in_features=36, out_features=19, bias=True)
    (13): LeakyReLU(negative_slope=0.01)
    (14): Linear(in_features=19, out_features=91, bias=True)
    (15): Tanhshrink()
    (16): Linear(in_features=91, out_features=14, bias=True)
    (17): ELU(alpha=1.0)
    (18): Linear(in_features=14, out_features=45, bias=True)
    (19): Softsign()
    (20): Linear(in_features=45, out_features=37, bias=True)
    (21): SiLU()
    (22): Linear(in_features=37, out_features=11, bias=True)
    (23): ReLU6()
    (24): Linear(in_features=11, out_features=21, bias=True)
    (25): ReLU()
    (26): Linear(in_features=21, out_features=16, bias=True)
    (27): ReLU6()
    (28): Linear(in_features=16, out_features=9, bias=True)
    (29): Softsign()
    (30): Linear(in_features=9, out_features=96, bias=True)
    (31): Tanhshrink()
    (32): Linear(in_features=96, out_features=1, bias=True)
    (33): Hardtanh(min_val=-1.0, max_val=1.0)
  )
)