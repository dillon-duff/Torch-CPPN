RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=24, bias=True)
    (1): Hardsigmoid()
    (2): Linear(in_features=24, out_features=73, bias=True)
    (3): Tanh()
    (4): Linear(in_features=73, out_features=85, bias=True)
    (5): ReLU6()
    (6): Linear(in_features=85, out_features=72, bias=True)
    (7): Hardswish()
    (8): Linear(in_features=72, out_features=94, bias=True)
    (9): LeakyReLU(negative_slope=0.01)
    (10): Linear(in_features=94, out_features=84, bias=True)
    (11): Mish()
    (12): Linear(in_features=84, out_features=88, bias=True)
    (13): Tanh()
    (14): Linear(in_features=88, out_features=31, bias=True)
    (15): Tanh()
    (16): Linear(in_features=31, out_features=63, bias=True)
    (17): Mish()
    (18): Linear(in_features=63, out_features=3, bias=True)
    (19): SELU()
    (20): Linear(in_features=3, out_features=54, bias=True)
    (21): Identity()
    (22): Linear(in_features=54, out_features=51, bias=True)
    (23): GELU(approximate='none')
    (24): Linear(in_features=51, out_features=37, bias=True)
    (25): SELU()
    (26): Linear(in_features=37, out_features=89, bias=True)
    (27): Hardshrink(0.5)
    (28): Linear(in_features=89, out_features=16, bias=True)
    (29): Softshrink(0.5)
    (30): Linear(in_features=16, out_features=34, bias=True)
    (31): Hardshrink(0.5)
    (32): Linear(in_features=34, out_features=32, bias=True)
    (33): Tanhshrink()
    (34): Linear(in_features=32, out_features=32, bias=True)
    (35): SiLU()
    (36): Linear(in_features=32, out_features=65, bias=True)
    (37): ReLU()
    (38): Linear(in_features=65, out_features=75, bias=True)
    (39): Softsign()
    (40): Linear(in_features=75, out_features=39, bias=True)
    (41): SELU()
    (42): Linear(in_features=39, out_features=14, bias=True)
    (43): Tanhshrink()
    (44): Linear(in_features=14, out_features=99, bias=True)
    (45): Identity()
    (46): Linear(in_features=99, out_features=16, bias=True)
    (47): LeakyReLU(negative_slope=0.01)
    (48): Linear(in_features=16, out_features=75, bias=True)
    (49): Softshrink(0.5)
    (50): Linear(in_features=75, out_features=1, bias=True)
    (51): RReLU(lower=0.125, upper=0.3333333333333333)
  )
)