RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=33, bias=True)
    (1): Hardsigmoid()
    (2): Linear(in_features=33, out_features=87, bias=True)
    (3): Softplus(beta=1, threshold=20)
    (4): Linear(in_features=87, out_features=4, bias=True)
    (5): ReLU()
    (6): Linear(in_features=4, out_features=48, bias=True)
    (7): Mish()
    (8): Linear(in_features=48, out_features=66, bias=True)
    (9): CELU(alpha=1.0)
    (10): Linear(in_features=66, out_features=26, bias=True)
    (11): Tanhshrink()
    (12): Linear(in_features=26, out_features=50, bias=True)
    (13): RReLU(lower=0.125, upper=0.3333333333333333)
    (14): Linear(in_features=50, out_features=64, bias=True)
    (15): LeakyReLU(negative_slope=0.01)
    (16): Linear(in_features=64, out_features=8, bias=True)
    (17): GELU(approximate='none')
    (18): Linear(in_features=8, out_features=35, bias=True)
    (19): PReLU(num_parameters=1)
    (20): Linear(in_features=35, out_features=1, bias=True)
    (21): SiLU()
    (22): Linear(in_features=1, out_features=1, bias=True)
    (23): PReLU(num_parameters=1)
  )
)