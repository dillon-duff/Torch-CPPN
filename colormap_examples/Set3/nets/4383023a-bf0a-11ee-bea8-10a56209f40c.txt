RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=78, bias=True)
    (1): Hardtanh(min_val=-1.0, max_val=1.0)
    (2): Linear(in_features=78, out_features=5, bias=True)
    (3): Hardtanh(min_val=-1.0, max_val=1.0)
    (4): Linear(in_features=5, out_features=35, bias=True)
    (5): LogSigmoid()
    (6): Linear(in_features=35, out_features=79, bias=True)
    (7): Hardshrink(0.5)
    (8): Linear(in_features=79, out_features=31, bias=True)
    (9): SiLU()
    (10): Linear(in_features=31, out_features=50, bias=True)
    (11): Softplus(beta=1, threshold=20)
    (12): Linear(in_features=50, out_features=14, bias=True)
    (13): Tanh()
    (14): Linear(in_features=14, out_features=5, bias=True)
    (15): Identity()
    (16): Linear(in_features=5, out_features=47, bias=True)
    (17): CELU(alpha=1.0)
    (18): Linear(in_features=47, out_features=83, bias=True)
    (19): Mish()
    (20): Linear(in_features=83, out_features=88, bias=True)
    (21): LeakyReLU(negative_slope=0.01)
    (22): Linear(in_features=88, out_features=77, bias=True)
    (23): SELU()
    (24): Linear(in_features=77, out_features=21, bias=True)
    (25): ELU(alpha=1.0)
    (26): Linear(in_features=21, out_features=17, bias=True)
    (27): SiLU()
    (28): Linear(in_features=17, out_features=19, bias=True)
    (29): Identity()
    (30): Linear(in_features=19, out_features=1, bias=True)
    (31): Hardshrink(0.5)
  )
)