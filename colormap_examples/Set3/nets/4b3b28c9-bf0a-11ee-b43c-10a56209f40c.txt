RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=3, bias=True)
    (1): Hardshrink(0.5)
    (2): Linear(in_features=3, out_features=61, bias=True)
    (3): Tanh()
    (4): Linear(in_features=61, out_features=24, bias=True)
    (5): RReLU(lower=0.125, upper=0.3333333333333333)
    (6): Linear(in_features=24, out_features=69, bias=True)
    (7): Softsign()
    (8): Linear(in_features=69, out_features=54, bias=True)
    (9): Tanh()
    (10): Linear(in_features=54, out_features=65, bias=True)
    (11): CELU(alpha=1.0)
    (12): Linear(in_features=65, out_features=57, bias=True)
    (13): Softplus(beta=1, threshold=20)
    (14): Linear(in_features=57, out_features=46, bias=True)
    (15): Hardtanh(min_val=-1.0, max_val=1.0)
    (16): Linear(in_features=46, out_features=24, bias=True)
    (17): Hardsigmoid()
    (18): Linear(in_features=24, out_features=58, bias=True)
    (19): LeakyReLU(negative_slope=0.01)
    (20): Linear(in_features=58, out_features=7, bias=True)
    (21): Identity()
    (22): Linear(in_features=7, out_features=33, bias=True)
    (23): Tanh()
    (24): Linear(in_features=33, out_features=75, bias=True)
    (25): ELU(alpha=1.0)
    (26): Linear(in_features=75, out_features=12, bias=True)
    (27): Hardtanh(min_val=-1.0, max_val=1.0)
    (28): Linear(in_features=12, out_features=65, bias=True)
    (29): Hardtanh(min_val=-1.0, max_val=1.0)
    (30): Linear(in_features=65, out_features=1, bias=True)
    (31): ELU(alpha=1.0)
  )
)