RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=75, bias=True)
    (1): Tanhshrink()
    (2): Linear(in_features=75, out_features=31, bias=True)
    (3): ReLU()
    (4): Linear(in_features=31, out_features=46, bias=True)
    (5): Hardsigmoid()
    (6): Linear(in_features=46, out_features=4, bias=True)
    (7): SiLU()
    (8): Linear(in_features=4, out_features=55, bias=True)
    (9): Tanhshrink()
    (10): Linear(in_features=55, out_features=54, bias=True)
    (11): RReLU(lower=0.125, upper=0.3333333333333333)
    (12): Linear(in_features=54, out_features=74, bias=True)
    (13): ReLU6()
    (14): Linear(in_features=74, out_features=134, bias=True)
    (15): Tanh()
    (16): Linear(in_features=134, out_features=118, bias=True)
    (17): SELU()
    (18): Linear(in_features=118, out_features=56, bias=True)
    (19): ELU(alpha=1.0)
    (20): Linear(in_features=56, out_features=40, bias=True)
    (21): Softplus(beta=1, threshold=20)
    (22): Linear(in_features=40, out_features=11, bias=True)
    (23): Hardshrink(0.5)
    (24): Linear(in_features=11, out_features=1, bias=True)
    (25): Softplus(beta=1, threshold=20)
  )
)