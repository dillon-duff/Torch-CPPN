RandomNetwork(
  (layers): Sequential(
    (0): Linear(in_features=3, out_features=111, bias=True)
    (1): Identity()
    (2): Linear(in_features=111, out_features=98, bias=True)
    (3): RReLU(lower=0.125, upper=0.3333333333333333)
    (4): Linear(in_features=98, out_features=145, bias=True)
    (5): SiLU()
    (6): Linear(in_features=145, out_features=127, bias=True)
    (7): Tanh()
    (8): Linear(in_features=127, out_features=134, bias=True)
    (9): Softplus(beta=1, threshold=20)
    (10): Linear(in_features=134, out_features=49, bias=True)
    (11): PReLU(num_parameters=1)
    (12): Linear(in_features=49, out_features=143, bias=True)
    (13): ReLU()
    (14): Linear(in_features=143, out_features=70, bias=True)
    (15): LogSigmoid()
    (16): Linear(in_features=70, out_features=32, bias=True)
    (17): LeakyReLU(negative_slope=0.01)
    (18): Linear(in_features=32, out_features=103, bias=True)
    (19): SELU()
    (20): Linear(in_features=103, out_features=127, bias=True)
    (21): Hardswish()
    (22): Linear(in_features=127, out_features=67, bias=True)
    (23): Tanhshrink()
    (24): Linear(in_features=67, out_features=20, bias=True)
    (25): Mish()
    (26): Linear(in_features=20, out_features=1, bias=True)
    (27): ELU(alpha=1.0)
  )
)